rm(list = ls(all = TRUE))
# load libraries
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(subplot)
install.packages('subplot')
install.packages("subplot")
# This script draws rarefaction curves/sampling coverage curves, and explores how we can subsample dataset to the same level of sampling completeness.
# All analyses rely on transposing the concepts of species richness estimation to interaction richness.
rm(list = ls(all = TRUE))
# load libraries
library(iNEXT)
library(dplyr)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(grid)
library(ggrepel)
library(cowplot)
# define working directory
WK_DIR <- getwd()
DAT_DIR <- "../../../data/30JAN21" # change path to your working directory if need be
OUT_DIR <- "../outputs"
# load data
all_obs <- read.table(paste0(DAT_DIR, "/all_web_interactions_20210130.csv"), header = TRUE, sep = ",", stringsAsFactors = FALSE)
sc_df <- read.csv(paste0(OUT_DIR, "/20230706_site_int-sampling-coverage.csv"), header = TRUE) # sampling completeness per site
install.packages("iNEXT")
install.packages(c("cowplot", "dplyr", "ggrepel", "iNEXT", "tidyr"))
rm(list = ls(all = TRUE))
# load libraries
library(iNEXT)
library(dplyr)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(grid)
library(ggrepel)
library(cowplot)
# define working directory
WK_DIR <- getwd()
DAT_DIR <- "../../../data/30JAN21" # change path to your working directory if need be
OUT_DIR <- "../outputs"
# load data
all_obs <- read.table(paste0(DAT_DIR, "/all_web_interactions_20210130.csv"), header = TRUE, sep = ",", stringsAsFactors = FALSE)
sc_df <- read.csv(paste0(OUT_DIR, "/20230706_site_int-sampling-coverage.csv"), header = TRUE) # sampling completeness per site
View(sc_df)
min(sc_df$sc)
# What is the minimal sampling completeness we can have for these networks?
min_sc <- min(sc_df$sc)
min_sc
install.packages("dplyr")
install.packages("dplyr")
install.packages("tidyr")
# load libraries
library(iNEXT)
library(dplyr)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(grid)
library(ggrepel)
library(cowplot)
# define working directory
WK_DIR <- getwd()
DAT_DIR <- "../../../data/30JAN21" # change path to your working directory if need be
OUT_DIR <- "../outputs"
# load data
all_obs <- read.table(paste0(DAT_DIR, "/all_web_interactions_20210130.csv"), header = TRUE, sep = ",", stringsAsFactors = FALSE)
sc_df <- read.csv(paste0(OUT_DIR, "/20230706_site_int-sampling-coverage.csv"), header = TRUE) # sampling completeness per site
# if we'd pick a single value for sampling completeness, it should be the minimal value
min_sc <- min(sc_df$sc)
help(tribble)
# Does it take long to generate 50 subnetworks for each site?
rand_site <- sample(sc_df$Site, 1)
head(all_obs)
site_int <- all_obs %>% filter(Site == rand_site) %>%
group_by(Lower_Taxon, Upper_Taxon) %>% count()
head(site_int)
dim(unique(subset(site_int, select = c(Lower_Taxon, Upper_Taxon))))
estimateD(site_int, datatype = "abundance", base = "coverage")
help("estimateD")
int_FV_obs <- all_obs %>% filter(Web == "PL_FV")
hab_list <- sort(unique(int_FV_obs$Habitat))
hab_names <- c("Grassland", "Heathland", "Salt marsh", "Sand dune", "Scrub", "Woodland")
names(hab_names) <- hab_list
site_list <- sort(unique(int_FV_obs$Site)); nb_sites <- length(site_list)
triad_list <- sort(unique(int_FV_obs$Site[int_FV_obs$M_D_T == "triad"]))
monad_list <- sort(unique(int_FV_obs$Site[int_FV_obs$M_D_T == "monad"]))
triads_col <- c(brewer.pal(length(triad_list)-2, "Dark2"), brewer.pal(3, "Set2")[1:2])
names(triads_col) <- triad_list
sites_pch <- 1:(length(monad_list) + length(triad_list))
names(sites_pch) <- c(monad_list, triad_list)
# Is the number of interaction events a good proxy of the level of sampling completeness across sites? This is very unlikely.
# Let's take an illustration in the MDT dataset.
triad_name <- "Bystock"; monad_name <- "Wyeswood_Common"
# Both sites have a portion of their area covered with grassland (whether total or a third).
grassland_int <- int_FV_obs %>% filter(((Site == monad_name) | (Site == triad_name)) & (Habitat == "grassland")) %>%
group_by(Site, Lower_Taxon, Upper_Taxon) %>% count() %>%
ungroup() %>% spread(Site, n)
head(grassland_int)
test <_ iNewt(site_int)
test <- iNewt(site_int)
test <- iNext(site_int)
test <- iNEXT(site_int)
head(sc_df)
site_min_sc <- sc_df$Site[sc_df$sc == min_sc]
site_min_sc_int <- all_obs %>% filter(Site == site_min_sc) %>% group_by(Lower_Taxon, Upper_Taxon, Web) %>% count() %>% ungroup()
mdt_int <- all_obs %>% group_by(Site, Lower_Taxon, Upper_Taxon) %>% count() %>%
ungroup() %>% spread(Site, n)
head(mdt_int)
test <- estimateD(mdt_int)
test <- estimateD(mdt_int[, -c("Lower_Taxon", "Upper_Taxon")])
head(mdt_int[, -c("Lower_Taxon", "Upper_Taxon")])
head(mdt_int[, -c("Lower_Taxon", "Upper_Taxon")])
site_names <- unique(all_obs$Site)
test <- estimateD(mdt_int[, site_names])
site_names
test <- estimateD(mdt_int[, site_names])
mdt_int <- all_obs %>% group_by(Site, Lower_Taxon, Upper_Taxon) %>% count() %>% ungroup() %>% spread(Site, n)
test <- estimateD(mdt_int[, site_names])
head(mdt_int)
site_names <- sort(unique(all_obs$Site))
site_names
mdt_int[, "Arne"]
head(mdt_int[, site_names])
test <- estimateD(mdt_int[, site_names])
site_names <- iNEXT(unique(all_obs$Site))
test <- iNEXT(mdt_int[, site_names])
# This script draws rarefaction curves/sampling coverage curves, and explores how we can subsample dataset to the same level of sampling completeness.
# All analyses rely on transposing the concepts of species richness estimation to interaction richness.
rm(list = ls(all = TRUE))
# load libraries
library(iNEXT)
library(dplyr)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(grid)
library(ggrepel)
library(cowplot)
# define working directory
WK_DIR <- getwd()
DAT_DIR <- "../../../data/30JAN21" # change path to your working directory if need be
OUT_DIR <- "../outputs"
# load data
all_obs <- read.table(paste0(DAT_DIR, "/all_web_interactions_20210130.csv"), header = TRUE, sep = ",", stringsAsFactors = FALSE)
sc_df <- read.csv(paste0(OUT_DIR, "/20230706_site_int-sampling-coverage.csv"), header = TRUE) # sampling completeness per site
site_names <- sort(unique(all_obs$Site))
mdt_int <- all_obs %>% group_by(Site, Lower_Taxon, Upper_Taxon) %>% count() %>% ungroup() %>% spread(Site, n)
test <- iNEXT(mdt_int[, site_names])
is(mdt_int[, site_names])
is(mdt_int[, site_names])
is.data.frame(mdt_int[, site_names])
is.numeric(mdt_int[, site_names])
mat_int_site <- as.data.frame(mdt_int[, site_names])
mat_int_site <- as.data.frame(mdt_int[, site_names])
test <- iNEXT(mat_int_site)
test <- iNEXT(mdt_int[, c(4, 5)])
mdt_int <- subset(mdt_int, select = site_names)
test <- estimateD(mdt_int)
head(mdt_int)
head(as.matrix(mdt_int))
site_names <- sort(unique(all_obs$Site))
mdt_int <- all_obs %>% group_by(Site, Lower_Taxon, Upper_Taxon) %>% count() %>% ungroup() %>% spread(Site, n)
# a data frame for interaction names
mdt_int_names <- mdt_int %>% select(Lower_Taxon, Upper_Taxon)
mdt_int_names$Int_ID <- paste("Int", 1:nrow(mdt_int_names), sep = "_")
mdt_int <- subset(mdt_int, select = site_names)
mdt_int <- subset(mdt_int, select = site_names); rownames(mdt_int) <- mdt_int_names$Int_ID
head(mdt_int)
mdt_int <- as.matrix(subset(mdt_int, select = site_names)); rownames(mdt_int) <- mdt_int_names$Int_ID
head(mdt_int)
test <- estimateD(mdt_int)
test <- estimateD(mdt_int[, c(site_min_sc, rand_site)])
# Does it take long to generate 50 subnetworks for each site?
rand_site <- sample(sc_df$Site, 1)
########################
# if we'd pick a single value for sampling completeness, it should be the minimal value
min_sc <- min(sc_df$sc)
site_min_sc <- sc_df$Site[sc_df$sc == min_sc]
reps <- 50 # number of replicates
# Does it take long to generate 50 subnetworks for each site?
rand_site <- sample(sc_df$Site, 1)
test <- estimateD(mdt_int[, c(site_min_sc, rand_site)])
mdt_int[, c(site_min_sc, rand_site)]
test <- iNEXT(mdt_int)
test <- estimateD(mdt_int)
install.packages(c("pryr", "TeachingDemos"))
rm(list = ls(all = TRUE))
# load libraries
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(TeachingDemos)
library(pryr)
library(lme4)
# define working directories
DAT_DIR <- "../../data"
OUT_DIR <- "../outputs"
# load data
setwd(DAT_DIR)
# all_obs <- read.table("all_web_interactions_final.txt", header = TRUE, sep = "\t", stringsAsFactors = FALSE)
all_obs <- read.table(paste(DAT_DIR, "all_web_interactions.csv", sep = "/"), header = TRUE, sep = ",", stringsAsFactors = FALSE)
int_FV_obs <- all_obs %>% filter(Web == "PL_FV")
# load null model outcomes
nm1_metrics <- read.csv(paste(OUT_DIR, "null_model_1_metrics_20200608.csv", sep = "/"), header = TRUE, stringsAsFactors = FALSE)
nm2_metrics <- read.csv(paste(OUT_DIR, "null_model_2_metrics_20200608.csv", sep = "/"), header = TRUE, stringsAsFactors = FALSE)
nm1_sc_metrics <- read.csv(paste(OUT_DIR, "null_model_1_sc_metrics_20200608.csv", sep = "/"), header = TRUE, stringsAsFactors = FALSE)
nm2_sc_metrics <- read.csv(paste(OUT_DIR, "null_model_2_sc_metrics_20200608.csv", sep = "/"), header = TRUE, stringsAsFactors = FALSE)
# all_obs <- read.table("all_web_interactions_final.txt", header = TRUE, sep = "\t", stringsAsFactors = FALSE)
all_obs <- read.table(paste(DAT_DIR, "all_web_interactions.csv", sep = "/"), header = TRUE, sep = ",", stringsAsFactors = FALSE)
# all_obs <- read.table("all_web_interactions_final.txt", header = TRUE, sep = "\t", stringsAsFactors = FALSE)
all_obs <- read.table(paste(DAT_DIR, "all_web_interactions.csv", sep = "/"), header = TRUE, sep = ";", stringsAsFactors = FALSE)
list.files(DAT_DIR)
getwd()
